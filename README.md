# VAPID
The **V**isual and **A**uditory **P**rocessed **I**dentification **D**ataset (VAPID) is a human-curated shared task collection of audiovisual media intended for computational research in natural language processing (NLP) to create models for domaisns such as automatic speech reconigition, speech translation, audio description, and speaker verification or diarization.

Currently, to most AI models, audiovisual media is **vapid**—or perceived as unstimulating—because they are hardly trained on videos accompanied by audio, and we are trying to change that.
